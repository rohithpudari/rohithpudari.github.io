<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://rohithpudari.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rohithpudari.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-06-18T14:28:42+00:00</updated><id>https://rohithpudari.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Aligning Documentation and Q&amp;amp;A Forum through Constrained Decoding with Weak Supervision</title><link href="https://rohithpudari.github.io/blog/2023/dosa/" rel="alternate" type="text/html" title="Aligning Documentation and Q&amp;amp;A Forum through Constrained Decoding with Weak Supervision"/><published>2023-10-20T12:01:00+00:00</published><updated>2023-10-20T12:01:00+00:00</updated><id>https://rohithpudari.github.io/blog/2023/dosa</id><content type="html" xml:base="https://rohithpudari.github.io/blog/2023/dosa/"><![CDATA[<p><em>This text was created from my paper titled “Aligning Documentation and Q&amp;A Forum through Constrained Decoding with Weak Supervision” accepted in ICSME 2023. The paper is available <a href="https://ieeexplore.ieee.org/abstract/document/10336308">here</a>.</em></p> <p>Stack Overflow (SO for short) is a popular Q&amp;A forum for software developers. It contains a wealth of information on a wide range of programming topics, but it can be difficult to find the relevant information quickly and efficiently. Moreover, SO users often reference external websites like blogs, tutorials, and documentation in their answers. SO plays a supplementaty role to official documentation (DOC for short) by offering practical examples. From our preliminary analysis, we found that 53 out of 200 sampled StackOverflow answers included at least one documentation (DOC) link. The process fo simultaneously searching for relevant documentation and StackOverflow posts is time-consuming and inefficient due to their disconnected nature.</p> <p>To solve this problem, we proposed DOSA (short for Documentation &amp; StackOverflow Alignment), a novel approach to turn LLMs into a domain-specific retriever capable of determining the specific section within the DOC to which a given SO question belongs.</p> <p>Here is the overview of our approach.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/DOSA/overview-480.webp 480w, /assets/img/DOSA/overview-800.webp 800w, /assets/img/DOSA/overview-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/DOSA/overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>We first extract categories and subcategories from the documentation. Here is a snippet from the Flask documentation,</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/DOSA/doc_example-480.webp 480w, /assets/img/DOSA/doc_example-800.webp 800w, /assets/img/DOSA/doc_example-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/DOSA/doc_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Section headings categorize text within them, like ‘API’ as the top-level category and sub-headings as sub-categories, such as ‘JSON Support.’ Text within the API category is labeled ‘API,’ and text under the JSON Support sub-category is labeled ‘JSON Support’ as well as ‘API.’ We group three sentences together to create an example and continue this pattern to form a tree-like structure. As a starting point, we chose two popular topics, Python and Flask, to study the feasibility of our method.</p> <p>We then collect StackOverflow posts related to Python and Flask for our evaluation. We randomly sampled 200 posts from the Stack Overflow dataset, focusing on both the ‘Python’ and ‘Flask’ tags. Two of our authors independently labelled these posts to specific topics within Python or Flask documentation, using categories and subcategories extracted from the documentation as labels.</p> <p>We then fine-tune the LLM on the documentation corpus. We use the fine-tuned LLM to generate labels for StackOverflow posts. There is no existing dataset mapping between StackOverflow questions and documentation. Conventional ML approaches require extensive human-labeled data, which isn’t available. That’s why DOSA uses LLMs to perform this task in a zero-shot manner, leveraging their language comprehension capabilities fine-tuned on Documentation to establish connections to StackOverflow questions without explicit training data.</p> <p>The first part of our DOSA approach involves weak supervision. We fine-tune the model using data scraped from documentation. Later, we test it on a manually labeled dataset of StackOverflow questions. While our training and evaluation data differ, they share similarities. This demonstrates the essence of weak supervision, where the model learns from text extracted from documentation and applies this knowledge to label Stack Overflow questions using categories and subcategories from the documentation</p> <p>When given an input of our stack overflow question on posting json in flask the expected category and sub-category from the documentation are predicted. LLMs select one token from its entire vocabulary at each decoding step to generate the final output. weak supervision alone is not enough to align stackoverflow questions to documentation categories and sub-categories due to hallucinations from LLMs. so, constrained decoding is introduced to limit the LLM’s vocabulary. Constrained decoding incorporates domain terminology, ensuring that generated tokens align with the labels extracted from the documentation. constrained decoding only affects the generation process and doesn’t impact the fine-tuning process in any way.</p> <p>We evaluated DOSA on two documentation sites, Python and Flask. We compared DOSA to baselines such as Pyserini, a popular information retrieval technique, and LLMs (GPT-2 and LLaMA) including the performance of each component of DOSA (i.e., weak supervision and constrained decoding). We used the Precision and recall scores to evaluate the performance of each approach.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/DOSA/results-480.webp 480w, /assets/img/DOSA/results-800.webp 800w, /assets/img/DOSA/results-1400.webp 1400w, " sizes="95vw" type="image/webp"/> <img src="/assets/img/DOSA/results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Our approach offers a practical solution to the persisting problem of aligning SO to DOC, providing a crucial bridging mechanism between advanced LLMs and the realm of precise information retrieval. We established a foundation for aligning various documentation resources within the same domain. Future work can capitalize on these findings to not only amplify the generalizability, performance, and utility of the proposed approach but also to extend its application to broader domains beyond programming. Exploring innovative methods for categorizing diverse types of technical documents is also a promising avenue for future exploration.</p>]]></content><author><name></name></author><category term="paper-summary"/><category term="documentation"/><category term="stackoverflow"/><summary type="html"><![CDATA[A blog post on my paper accepted in ICSME 2023]]></summary></entry><entry><title type="html">Copilot to pilot</title><link href="https://rohithpudari.github.io/blog/2023/masters/" rel="alternate" type="text/html" title="Copilot to pilot"/><published>2023-03-10T12:01:00+00:00</published><updated>2023-03-10T12:01:00+00:00</updated><id>https://rohithpudari.github.io/blog/2023/masters</id><content type="html" xml:base="https://rohithpudari.github.io/blog/2023/masters/"><![CDATA[<p><em>This text was created from my defense presentation of my Master’s thesis, given at the University of Victoria, 23 August 2022. The thesis titled “AI Supported Software Development: Moving Beyond Code Completion” is available <a href="http://hdl.handle.net/1828/14155">here</a>.</em></p> <p>full text: <strong>AI-Supported Software Development: From Copilot to Pilot</strong></p> <p><strong>Introduction</strong></p> <p>The rise of AI-supported programming tools like GitHub’s Copilot marks a significant step in software development. Leveraging OpenAI’s Codex, Copilot assists developers by predicting and suggesting code snippets based on context. This tool represents a broader trend towards AI systems that can enhance software development productivity. However, the journey from AI-supported code completion to AI-driven software engineering involves overcoming several limitations. This blog post summarizes a research paper that investigates these limitations and proposes a taxonomy for understanding the boundaries and potential of AI-supported code completion tools.</p> <p><strong>Background</strong></p> <p>Copilot is a pioneering AI tool integrated within IDEs to suggest code based on a few lines of comments or code. It uses a large language model trained on vast amounts of code from public repositories. While Copilot excels at understanding context and semantics, software development requires more than just coding. It involves following best practices, avoiding code smells, and making rational design decisions.</p> <p><strong>Study Design</strong></p> <p>The research explored Copilot’s ability to follow language idioms and avoid code smells. Two main research questions were addressed:</p> <ol> <li><strong>RQ-1: What are the current boundaries of AI-supported code completion tools?</strong> <ul> <li><strong>RQ-1.1: How do AI-supported code completion tools manage programming idioms?</strong></li> <li><strong>RQ-1.2: How do AI-supported code completion tools manage to suggest non-smelly code?</strong></li> </ul> </li> </ol> <p>To answer these questions, the study focused on Python idioms and JavaScript best practices. The evaluation involved testing Copilot’s suggestions against established coding standards and best practices.</p> <p><strong>Results</strong></p> <p>The findings revealed significant limitations in Copilot’s ability to follow idioms and avoid code smells:</p> <ol> <li><strong>Pythonic Idioms</strong>: Out of 25 tested idioms, Copilot suggested the idiomatic approach as the top suggestion in only 2 instances. In 8 cases, the idiomatic way appeared within the top 10 suggestions, but in the majority of cases (15 out of 25), the idiomatic approach was absent.</li> <li><strong>JavaScript Code Smells</strong>: Copilot suggested the best practice as the top suggestion in only 3 out of 25 instances. In 5 cases, the best practice was among the top 10 suggestions, but in 17 scenarios, it was not present at all.</li> </ol> <p>These results indicate that current AI-supported code completion tools are not yet capable of consistently suggesting idiomatic or best-practice code, even though these practices are widely used in public repositories.</p> <p><strong>Taxonomy of Software Abstractions</strong></p> <p>The study proposes a taxonomy to understand the capabilities and limitations of AI-supported code completion tools. This taxonomy includes six levels of software abstractions:</p> <ol> <li><strong>Syntax Level</strong>: Ensuring suggested code is syntactically correct without compilation errors.</li> <li><strong>Correctness Level</strong>: Providing solutions that are not necessarily optimal but solve the given programming task.</li> <li><strong>Paradigms and Idioms Level</strong>: Using common paradigms and language idioms in code suggestions.</li> <li><strong>Code Smells Level</strong>: Avoiding common code smells and suggesting the most optimized version of the code.</li> <li><strong>Design Level</strong>: Supporting module-level and system-level design choices, including test cases, continuous integration, and adherence to coding style guidelines.</li> </ol> <p><strong>Discussion</strong></p> <p>The transition from code completion to AI-supported software engineering is challenging. Gathering sufficient training data, updating models to reflect evolving coding practices, and enabling multi-file input are crucial steps. Current AI tools like Copilot perform well at lower levels of abstraction but struggle with higher-level design tasks. Effective AI-supported code completion tools have the potential to significantly increase software development productivity, but achieving this requires overcoming these challenges. Enhancing training data quality by including verified sources and filtering out known flaws, integrating code review tools to improve suggestion quality, and adopting active learning approaches to learn a user’s context are some ways to improve these tools.</p> <p><strong>Implications</strong></p> <p><strong>For Practitioners</strong>:</p> <ul> <li><strong>Pre-training the LLM</strong>: Enhancing training data quality by including verified sources and filtering out known flaws.</li> <li><strong>Code Completion Time</strong>: Integrating code review tools to improve suggestion quality and adopting active learning approaches to learn a user’s context.</li> </ul> <p><strong>For Researchers</strong>:</p> <ul> <li><strong>Moving Beyond Tokens</strong>: Developing models that work at the code block or file level, leveraging recent advances like the chain of thought process.</li> <li><strong>Design Patterns and Architectural Tactics</strong>: Training models to understand and suggest appropriate design choices.</li> </ul> <p>Developing models that understand and suggest appropriate design choices, including design patterns and architectural tactics, is essential. AI-supported programming tools like Copilot represent a promising step towards more productive and efficient software development. However, significant challenges remain in moving beyond code completion to AI-supported software engineering. Addressing these challenges requires further research, better training data, and advancements in AI capabilities. The vision of AI-driven software engineering, where AI assists in complex design tasks, is achievable but requires continued innovation and development.</p> <p><strong>Conclusion</strong></p> <p>AI-supported programming tools like Copilot represent a promising step towards more productive and efficient software development. However, significant challenges remain in moving beyond code completion to AI-supported software engineering. Addressing these challenges requires further research, better training data, and advancements in AI capabilities. The vision of AI-driven software engineering, where AI assists in complex design tasks, is achievable but requires continued innovation and development.</p>]]></content><author><name></name></author><category term="paper-summary"/><category term="copilot"/><category term="thesis"/><summary type="html"><![CDATA[A blog post on my masters thesis]]></summary></entry></feed>